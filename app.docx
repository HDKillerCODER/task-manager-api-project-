Technical session - APIs-20240814_170214-Meeting Recording
August 15, 2024, 9:02PM
1h 46m 2s

Jayaraman, Babu   0:03
I don't know too early for us.

Gadde, Ramesh started transcription

Jayaraman, Babu   0:06
I just got up 7:00 o'clock here for my cell phone there.

Mackellar, Alasdair   0:09
And make are you looking for the L part meeting?
If you are, this is, you're in the you're in the wrong one.

Albert, Mike   0:13
Yes, I didn't.

Mackellar, Alasdair   0:15
You need to drop out of this one and join the other meeting.
There's two.
There's two calls at the same time, and your diary.

Albert, Mike   0:22
Thank you, Alistair.

Mackellar, Alasdair   0:22
I think you've you've got the same diary as me, so thanks Mike.

Albert, Mike   0:25
Yeah.
I I take I picked the wrong one.
Thanks, Alex.

Mackellar, Alasdair   0:29
Take their online.

Albert, Mike   0:29
Appreciate it. Bye.

Mackellar, Alasdair   0:29
Yeah, you ain't 5050.
So speak to you later.

Albert, Mike   0:33
Bye.

Jayaraman, Babu   0:33
Yep, happy to be here. Uh.

Mackellar, Alasdair   0:38
Sorry, but we have scared off one of your attendees there. Apologies.

Jayaraman, Babu   0:42
Not a problem.
I'm also waiting for one of my architect to be joining.
I bit early here, 77 AM here, so we'll give him few more minutes then it's not few more.
Just will give another one or two minutes.
Then we'll get started.
OK, let's get started.
I'll introduce myself.
Some of you know already.
I'm Babu.
I'm managing the Infinity Connect CSP and Service view application.
These these three applications depend on on V1C, so midrange applications.
These applications are running in across three regions in Australia.
Primarily, no.
We started with Australia earlier and then it is running in the UK region as well as it's more to the North America region three years before yeah especially I'm sure Indu set up this call for the support team to understand what we are doing with for MPMS high availability.
I believe the support team is taking care of the clients in the North America.
If PC and FPC regions, in addition to that, the same team, what I understand, Louise and Robert, I think is in the call in addition to that, Rajneesh team is going to take care of the MPMS, the MasterCard client in North America, pretty much the applications, what you're supporting currently for EPC, the the same thing, they're going to support it, the server, the application, the architecture almost same because we are using the single source code and deploying in a multiple regions or multiple clients across the globe.
So in terms of the service code, service view or Infinity Connect or CSP) the code it remains same.
Yeah, only we are adding the high availability on top of that Infinity Connect application and also CSP).
Yeah.
The service view there is no change because service view is not supporting the high availability.
Uh, in terms of the Infinity Connect and the CSP, whatever we provided already the documentation Rajneesh and they think you're in the call as well, whatever you provided the documentation is remain same, yeah for including the service also there's not going to be changing anything what I what we wanted to cover in this meeting especially among having Richard who is my architect for this CSP and Infinity Connect application and as well though his name nickname is Papa is going to join quickly as well.
So he will.
He's also my architect for the Infinity Connect application, so both will be giving you an overview about the high availability and how you're supporting for the Infinity Connect and CSP.
I'll hand over this call to Richard.
He'll be proceeding from there and then he'll be handing over to a Papo.
And then he will be taking over some of this things from there, Richard.

Kernahan, Richard   4:15
Great.
Thanks share my screen.
We go alright, I'll give you an overview of the high the caching system as we're implementing it for MPMS.
And.
Took quite a lot with this diagram, but I'll tell you the topics that we're going to cover and then I'll just pause briefly just to make sure that that's in line with what your expectations are and make sure you know we're gonna be covering the right things.
I'll talk about the architecture and overview.
We'll talk about inquiries of how the inquiries work from customers. The database?
Uh, how updates work and forwarding the near real time messages that how we keep In Sync between the mainframe and the midrange?
The caching system.
How we load extract files from the from from the mainframe?
Umm.
Sensing when P1C is up or down and how we know whether or not we're standing in for P1C and briefly cover all the different types of problems that can occur throughout the architecture.
So don't you just Rick Post to just make sure is that in my if anybody saying no that's what we want to cover something else.
Please let me know now.

Zamora, Oswaldo   5:53
Ohh, I'd Richard.
Sorry, it's a it's people here if you want, I can go start with the Infinity Connect introduction and then I'll send it over to you to explain more in more detail about the the data load process and how we synchronize it with.
I see database just to do a quick question.

Kernahan, Richard   6:13
Sure, if you like to do that, yeah, sure.
Go ahead please.

Zamora, Oswaldo   6:15
Yeah.
Thank you.
It's.
I'm gonna.
I'm gonna share my screen.
See looks.
Umm.
You can you see my screen.
String to organize here.

Kernahan, Richard   7:04
We've got to desktop over black desktop.

Jayaraman, Babu   7:05
We are able to, yeah.

Zamora, Oswaldo   7:08
Sorry.
I need this here.
And how, like we cannot present.
Maybe if I share the other screen, sorry.
Yeah, but if I show this screen work.
No, nothing.

Jayaraman, Babu   7:47
Yeah, that works.

Kernahan, Richard   7:48
Yeah, we see that.

Zamora, Oswaldo   7:49
Yeah, I think it's a bit small.
No, it's again.
It's that one.
Sorry for that.
Let me.
That's screens here.
Ohh Denis, maybe this one.
And let me know if it's if it's OK.

Jayaraman, Babu   8:18
Yeah, that looks better.

Zamora, Oswaldo   8:21
Yep.
OK. Thanks.
Ohm.
Yes, I first start with the brief interaction.
What is Infinity Infinity connect and you know Infinity Connect is FIS Enterprise middleware and it acts as a service mediator.
And in a service oriented architecture it helps connect service consumers like client applications, channels with service providers like P1C host and it it it helps.
It's a facilitate this integration through REST API by exposing rest endpoint with services.
These are built in JSON.
Sorry, in Java we using JSON message format and the functionality of the service links and key: service links is exposed through each of these services.
Now so each service link is exposed through its own this PIN.
And as part of this.
Message and protocol mediation and the application does authentication and authorization message transformation, validation and routing of the message from the source to the target.
And these endpoints are consumed by the client through rest endpoint format.
That looks like this service link is the first part of the the service path.
So you have the corporation number, the version of the API, and then the request code which is A3 character identifier of the service.
We use the same identifier like the one that is defined in P1C service link, so it's easy to know which service is being called.
For example, if the client wants to consume the.
GCD service, which means get cardholder details to get information about.
Uh, uh.
Part it will use the following URL.
Service link U3 this can be the corporation number, the version of the service, and then the GCD service ID.
It will send a request that looks like this.
It this request is defined in using the same and feels that are also defined in the service link copybooks and we try to use the same standard for naming and the response will look like this one.
That's how the the client will see the response with information about the request that time time it took to complete the the round trip call and the response to it tells if the service was successful or not.
Sincere means successful.
Any other number greater than 10 will mean that the service failed.
Then we have the information about.
Yeah, it's it's the the information about the service and the data that was requested like this case, data related to the other account and was sent in the request.
That's how it Infinity Connect API is look before the high availability enhancements.
So now that we.
And and has the application to support.
Yeah, I uh I available API but what we've done is we added our cache model here with services.
That is where the beloved in Java and they try to replicate the business logic defined in each of these services, service links and similar to the service links these cache service or replica services.
Accept MQ request and return also produce and your responses and the the information that they used to produce the response is obtained from the cache database which is also a new component.
That was added where we store the data that is extracted from B1C through uh tools and processes that Richard will the explain about and that's how we keep in synchronized.
We'll be keeping synchronized the the data.
Umm.
Umm, there's also, uh flag here. You'll see.
Also added in the application.
This flag is used to.
To identify when the application.
So if you need to connect is gonna be running instant standing mode or not.
So that depends on the P1C post availability.
If P1C is available, the request that comes from the client will will be routed to the P1C online service link.
If if you can connect, it detects the P1C is down for some reason, then the the message instead of send being sent to to the host is gonna be sent to the the cache module and the respective service service or cache service.
In this case, umm, the application also interacts now with a different systems.
So we have CSP customer select Bing if it wants to do ohm.
Uh, yeah, sorry.
Or wants to interact with HSM to do things like set get PIN or get CVV.
That's why we have the CSP application here and then we also have ID which is, uh information switching technology.
Application is also used to notify and synchronize changes made in services for card account statuses or things like balances or PIN offsets.
Hmm.
One important thing to note here is that, uh.
All these changes are transparent to the client, so that means that API in endpoint and request message format they they they they they are currently using they they won't be changed so.
And that's it for the changes.
And we have that list of cache services we have developed for FILICKY to support high availability for APIs.
The APIs that we have in IC we have around 380 APIs but out of all of them we only have these ones it into the cache model.
So this is these are the ones that we have converted actually converted from call to Java to run in.
In the Connect, we have 16 inquiry and 16 update services and the detail of.
And these services are shown in this table and if you can see it's it's a bit small, but we have here that 32 services sorted by request code.
Other description of what IT service DOT does the API version that we run of the service, the type of service?
If it's an inquiry only reads from the database in the cache database, or if it's an update.
If it's in add inserts also inserts the updates or deletes data.
We also have defined at the service level.
Uh flag called cash ohm status?
Uh, this is an indicator that as this, uh, three values uh, when it has an A value, it means that the service will be started as always on and it means that soon as the application starts it will permanently be.
Call instead of the P1C and we have also the E status which means enable and that means that the service would be called ohm only when there's a P1C outage by P1C outage we we check for 2/2 of them, the one is a planned outage which can be uh base global.
I'm sorry P1C patch or something you can happen also during implementation or Mainframe.
IPL outages?
Those aren't those are those are planned outages then we also have an planned outage which.
And these ones are are an expected, yeah.
Audies, which can be things like network failure or a problem with communicating with MQ or POC is simply not able to process certain transactions and in those cases we once you will reply with a fixed error message that will help us know that we need to route those messages to the respective cache services.
Umm.
And then the last status is it sables status, which means that the service won't be called.
So in the cache model and instead the message will be routed to P1C.
I'm here.
We have also the last two columns show the the services that we call in each application.
The CSP and IST you can see Ohh here for example.
The ECD uses a CB.
And service.
Uh, and uh, we have two other services to to get pin and set pin.
Those are the services that are called from CSP.
Same for IST.
We have this customer, CTU customer demographic update, which is an update service calls this this other and Services from IST.
And uh, yeah.
So I show you before, uh, about this flag this.
You wanna see and available flag?
Uh, which is a stand, uh standing standing mode flag and to show you a bit more about how that works, we have two different flow message flows.
Umm yeah, the normal flow is the one that where P1C not.
Sorry, where Infinity Connect will decide what to do with the request depending on the P1C availability.
So if you follow.
Can you make my cursor?
You see that when the rest API a recipe is called consume, uh, first thing that we do for all the API is we check for Umm main flag which we call corporation flag and this is one that will be enable or disable all the the cache model or cache cache cache services.
If it's disabled, it is like it disabled.
The message is sent to P1C if it's in enabled in the cache mode will be and he called and then add this.
The second flag will be checked and this is a flag that I show you before, which is defined at the service level and and here we we identify that the service as a disabled styles or not cash status.
Umm.
And then the request will be sent to P1C if it's always on, it will go directly to ohm, to the cache service and if it has an East titles, uh, well, it depends on and this third flat which is at standing flat, that it helps decide where the message finally will go if we need to be in standin mode and the message will be sent to because service otherwise it will be it will go to P1C.
And then we have another flow.
And that is that uses a cash driven flat which is called cache flag.
This flag is sent in the HTTP header of the request.
Client can decide to send it or not.
It's not an optional flag.
On the same note, the the corporation flag is is checked 1st to see if we are enabling or not the cache for.
For a corporation 50 sable, it goes to P1C.
If it's enabled, then this flag was sent by by the client will be evaluated, and if the client decides to call the cache service, this value will we discuss flag will be true, then the service will be executed, otherwise the message will be sent to P1C.
Yeah, I think that's a that's all from me.
So next Richard will explain the applications, tools and processes we used to keep the data synchronized in the cache database.
So over to you and Richard.

Kernahan, Richard   22:30
It's been OK.
I'm just gonna get back after the high level and start from the beginning in case anybody.
I'm gonna cover things from the beginning is if you don't know very much because I don't know how much everybody knows.
What are we doing here?
We've got umm MPMS client Europe.
We're running it on infrastructure in America.
The we're bringing 12 million cards over and going live in the next few weeks, so the.
We're running batches during, but essentially the middle of the day in Europe.
So at the beginning of the batch and the end of the batch, there's a time when P1C is not available, and during that time we could have thousands of requests coming in that can't be, umm it dealt with and that's not acceptable.
So we need to have availability through those periods, even though they're short.
We need, we need to cover them.
So that's what the hive variability.
Umm Ohh talk is about the solution to that is the P1C caching option.
You might hear it referred to as the caching system, PCO or the caching part of in Infinity Connect. Umm.
Client so publish showed you there's a Jason requests coming from the client to P1C through Infinity connect lots of inquiries and balances et cetera.
So they.
Come through as Jason requests, they get converted but from by Infinity Connect into a fixed format and send over MQ to to P1C the payments one card system and normally most of the time that's just gonna flow straight through so you can ignore the whole bottom half of the graph for normal operation this is just normal.
However, for that one or two minutes in the morning in the afternoon when P wants to isn't available, we need to we need to have high variability caching services inside Infinity Connect so.
These were new services that were built and they replicate the logic that's in the service link, so the service link so that individual services in the P1C and their identified by three letter name three letter names like LSR for lost and stolen and replacement card. Umm.
OK.
So those services that are in inside Infinity connect these cached services.
They're also called cache replicas because they're replicate some of the logic from 1C, so they do some of the logic, but not all of the logic of P1C, only enough that we can answer the questions or do do the we're trying to do the minimum job in the mid range area and then pass on the message back to P1C so that when it comes back up, it can do the rest of the job.
For example, lost and stolen, we will.
Uh, yeah.
Create a new account, give that back in the request to the customer, and then pass on that request to P1C.
When it comes back up again so that it can do all the rest of the housekeeping and and correct processing that to normally required for for a lost and stolen replacement card.
O we have.
In order for these inquiries to work, we have to get the data.
We don't have P1C, so we've got to have the data in a caching database.
Uh, essentially, let's talk about the rest of this diagram first.
From from P1C we extract data.
Uh, that those files are sent via FTP to a disk.
This disk is on one of the Infinity Connect servers.
Uh, obviously it's only one because we're although we've got 6 servers for load balancing etcetera across two data centers, only one of these servers is going to have the disk and have the files because only one of them can be controlling all of this loading into the database.
So these extract files come from P1C and we pull over all the data we need.
Not all the data from P1C, but the relevant data and put it in the database.
Then when we get an inquiry from the client, we can and so the question.
Here's the balances and all of the account information in the caching database that the inquiry caching service can read the database and respond accurately.
What do we have in the database?
The tables we have are ohh we've got something 50 tables, but a lot of them are parameters.
Not all of the parameters from P1C, but all of the ones that we need for the logic for these caching services to work are pulled over.
So we've got corporate parameters, product parameters BC 72, things like that.
If you're familiar with those kind of Mainframe tables, we've got probably, I don't know, 4040 parameter tables.
We've got accounts.
Uh, now, if you think about accounting, you can immediately realize that we've got fields in the account which don't change very often and and those that change quite frequently.
So the account data, although it's one table in P1C it's been split into two database tables for convenience, one is called ACCT account and the other one is is available balance well, so the account is uh like 4000 bytes long and has all of the name and address and things that don't change very often and then Avilla, available violence has only 300 bytes and it's got all the fields which are are gonna change with every transaction.
So every time an authorisation comes in we will get a I knew available balance record, but that's much smaller than the account record.
So we have to update the whole account record so there's accounts available.
We've got a list of authorisations we've got listed posted transactions, umm list of purged accounts.
Uh, there's multicurrency account tables and customer account tables.
Sorry customer customer tables as well.
So the customer master file, customer relationships, things like that.
Ohm.
OK, so they're the tables that are in the database.
So as you can see, we've got all of the data and the necessary for answering these inquiries that come in uh, when P1C is available.
So it's really a lot of work to go to in order to have the ability to just work for a few a few minutes a minute or 30 seconds or a couple of minutes, twice a day.
Uh, so that we can fill the gap.
Umm.
Something that's important about when we're going to send.
Messages through to P1C and when we're gonna serve them from the cache.
There's a difference between what we're going live with, which is shrunk down for to reduce risk, and what we what, where we eventually want to be.
So when we're going live, we're gonna use the caching services as little as possible, and we'll go live with messages flowing through from the client, through Infinity, Connect straight away over MQTT to P1C.
That'll be for inquiries and updates, so as much as possible most of the day.
Umm, we're going to be sending everything through to P1C for the most part.
And that's to reduce risk.
For example, we've got a a survey XT3 service here which looks at you know the list of accounts and transactions and things that has had a lot of changes.
And so until we've made sure that these cache replica replica services are perfect, we won't be, you know, putting them into full-time use.
Uh, but for that minute or two each morning and afternoon, they they they will be running.
Umm, but eventually, right?
That's initially right, but eventually where we want to get to is the inquiries will pretty much always be on.
So, you know, six months from now, I expect that any inquiry coming from the client is going to be served from the caching database and won't go to P1C.
So that'll offload, you know, take take a load off the off peak and see off the mainframe.
Updates.
However, I think in six months time I I expect updates will still probably flow straight through to P1C if at all possible and the reason for that is there's, there's a lot more, there's a lot more complex logic in the updates, so we can do the updates here in caching if we have to, but it's actually kind of lower risk and better to do it in P1C if you can because it takes care of all of the one of the possibilities.
All right, so I haven't talked about near real time messages, so let's talk about that now.
How do we keep this is related to how we keep 1C and the caching database In Sync O.
Each day we get extract files on a daily basis into the caching database.
So out of the batch will get all the latest files into the caching database, but things are happening all the time.
We've got an authorization coming through at any time, whenever the.
Whenever P1C gets an oath or any kind of transaction or as a change to an account.
There's a near real time message is sent via MQ.
Umm, so you'll hear people talk about NRT messages, these NRT near real time messages.
Anytime there's a change to an account will get an copy of that account record sent from P1C.
It takes like a second near real time means less than a second in this case 250 milliseconds or something like.
That's transmission time.
So people see generates a takes that basically extracts that single account record, sends it through MCQ and there's a process here which catches it and inserts it into the database, updates the database.
So if we've done an update to the database, will these services these caching services will update the database to keep it up to date enough so that enquiries have the right information?
But.
Gone.
No, but the the the UM system of record is P1C.
So if there's a change in P1C, we'll take the latest record and clobber the database with whatever P1C says it is, because that's the truth. Umm.
Right.
So that's what the near real time messages are and we have not those four accounts and available especially available in authorizations.
So when there's a transaction comes through, we get a new available balance record for the account and a new auth record to put into the into lists of author where we're holding here.
What else do we have?
You can get purged account records.
And we can't get customer if there's a customer maintenance change here, change to the customer details, we'll get some of those records.
Any that are affected get sent by by via MQTT and we'll update them straight away in the database so that keeps the database up to date.
So we've covered inquiries, updates, forwarding, OK, one last point I'll cover before I pause for any questions on what so far.
So for updates UM we have say I don't know 200,000 transactions a day maybe, uh, 98% of them are going to be inquiry.
So 2% of them are updates for an update, like a lost stolen replacement card LSR that comes in.
And suppose where it it comes in while he wants, he is down and it's handled by the cache replica.
What do we do?
What we do is we update we we create a new account number.
Now that account number is created in a new different range from what people see is using, so there's no, there's no conflict.
So we'll create a new account number, umm, and we'll set up that account.
We'll store that account in the caching database, but problem is what?
How does P1C know about it?
Right, P1C is down when it comes back up again in a minute.
We have to tell it what's happened O what we do is store the original request in MQ format.
Let me show you what that looks like briefly.
So the original request comes in.
This is the Jason that you saw earlier.
UM, right.
This is a request that comes in, and this is the response that goes back to the client, down to the bottom.
Here we see.
If you're not familiar with the Mainframe fixed format records, it looks something like that.
This one's an LSR.
Our response?
So that's what I see is doing.
It's converting the JSON into MQ.
We store that MQ record so the cache replica here does the LSR logic doesn't do all of it.
It does.
The bit that we need to do the minimum that we need to do update the database, create the new account record so that we can tell the customer.
Here's your new account number.
Umm.
Then we have to let P1C know, so we put that account number into that record.
So there is space for the new account number to go in that record, and then when P1C comes back up again, we forward that record to P1C so it can do the rest of the processing that we haven't done on the on the midrange side.
We also have a flag that's in those MQ messages, so the P1C can determine the difference between the message that comes through on a normal circumstances and flows straight through to P1C where it has to do everything because the caching service has not been involved and a message that came in was handled by the cache service got stored as later on been forwarded to P1C, in which case it might have to do things slightly differently.
In this case, LSR don't allocate a new account number because we've got an accountable already.
So use that one and do the rest of the processing.
Bearing that in mind, so there's some clever logic on the P1C side to handle forwarded messages from from the caching service.
In addition, though LSR is an example, it's a bit more complicated than that.
We might have a token as well for that account. So if we generated a token, there's no room in that message in that original message.
To revise that message and put a token in, there's just no room for it, so we have to have a second message that we store which says it's an field message.
It's a field set, set value message sets for this field on this account.
Set it to this value, so that's a second record that we store in the database, while P once used down and will forward that record after the first record.
So we we forward the first LSR record to P1C when we get back out an answer that says Yep that's done.
Then we forward the field and say, oh, by the way, here's a token for that account.
So please set that up and after PB, once he's finished doing that, each of those it has updated, if it's updated the account record, it will send back an account record through an IC and we clobber the database to overwrite the database with that record because that's the latest correct record.
Umm, I've got more to talk about.
Tell you what I'm going to talk about.
But I'm gonna pause for questions.
I'll talk about loading files here and how we know whether P1C is up or down, and then some of the problems that we might come across.
But let me just pause.
Are there any questions?
On.
Yep.
Any questions?
On what I've talked about so far.

Singh, Rajneesh   39:27
Ohh buddy Richard about the textract process.
How frequently is that running and what time I mean?

Kernahan, Richard   39:34
Yeah, I'll talk about the extract process next.
Yep.
Any other topics anybody wants to cover?

Gadde, Ramesh   39:43
So.

Mackellar, Alasdair   39:43
I think rection are be interested to hear some more on any potential risks or issues around the speed of when P1C comes back up the update and from the cache back to P1C.

Kernahan, Richard   40:00
OK, sync problems.
Basically, keeping things In Sync.

Mackellar, Alasdair   40:01
Yeah, basically.

Kernahan, Richard   40:02
Yep.

Mackellar, Alasdair   40:02
Yeah, yeah, yeah. Thanks.

Kernahan, Richard   40:03
OK, sure.
Thanks.
Yep, I'll do that.

Gadde, Ramesh   40:06
So I I know somebody was covered that there is a flax which will determine you know it has to go to a cache service or not.

Kernahan, Richard   40:21
Yep. Yeah, yeah.
But yeah, keep it.
So when how we know P1's up or down?
Yeah, I'm.
I'm gonna cover that as well.

Gadde, Ramesh   40:26
Yeah.
Thank you.

Kernahan, Richard   40:27
How we know people's up or down and what those flags, how the flags were?
Yes, thank you.
How about interacts?
OK, great.
All right. OK.
In our team, so we're actually up to extracting great.
Let's go back to that then.
You also need to come ohh, right.
And there's one other thing to cover as well.
Yeah. OK.
Alright, extracts alright.
So UM, initially uh, we have an empty database, so there's an initial load and then there's daily loads.
So the initial load, there's jobs that run on P1C and I extract the entire database of all the accounts, all of the available balance.
All of the posted transactions, the history goes back 18 months or whatever is configured for the client.
I think it's 18 months for PS and we get these large files we got I think for conversion we did 8.2 million accounts, 33 gigabytes of file.
So it's probably going to be 14 million accounts in total 6050 gig properly for the accounts file itself.
A valuable something like 10% the size of that and it transaction ones pretty big as well OS.
Initially, we're not running the cache and this is like before we go live.
Essentially, we will get all these large files they're sent to this disk.
This is an extra disk volume on the P1C designated P1C server.
It's a 500 GB which is plenty for several days and of of files.

Lan, Ben   42:05
That's good.
Which?

Kernahan, Richard   42:09
Umm.

Lan, Ben   42:10
Sounds it.

Kernahan, Richard   42:14
And right so the there's a program called there's an application called Pala, which is part of this whole caching system.
Umm, that is a it bulk loads these files into the database.
It shuffles the data into the caching database.
The only way to get 10s of millions of records into a database fast is using a program.
The Oracle program, SQL loader and so.
Yeah.
So that's what we use.
These files come across once there's a job there's like, as I said, 60 files or so Pala lows.
All of those files into the database and then we've got it primed with a certain amount of data.
Now then, we have a daily batch or every time the batch there are more records that are produced, another set of 60 files, but for the most part these are mostly well, there are some daily deltas which have just the changes for those datasets.
Umm, there's several different types or.
What do they call a parameters, product PARAMETERS, corporate parameters?
All the kind of P1C parameters.
This small, their daily replacement.
So whenever there's a change in product PARAMETERS or corporation parameters, any kind of the parameters that we get, all of those files come every day and we replace them every day.
So that's simple.
Then we've got things like transactions posted, transactions.
Well, we're not wiping them out.
We're going to keep the history of transactions and each day we get another file of what other transactions have been posted.
So we add those on to the to the list of transactions for authorisations, we get a replacement file because we have a list of authorizations from yesterday we need a new list today as as at the end of the batch or as a certain point of batch.
Actually this is the list of authorisations so that comes in this file.
Uh for customer accounts them are like permanent, so the initial load we get a full list of the customers and the customer master file essentially.
And every day we just get changes, so we might be able to, we might get some delete records, some add records or some updates.
Sure.
If we delete, we'll delete them from the database.
If it's in add or an update, we'll replace them in the database.
Essentially, replace whatever we have in the database with with those records for those customers those matching records.
If you know what I mean.
So that happens in daily batch.
Now, at what time does it happen? Umm.
It's so we.
This is a complex diagram, but it's it's not as it's not actually as complex as it looks, and we'll talk through it.
Let's focus on the the authorizations during the batch.
We have certain stages.
If you if you're not familiar with the the batch process and I'm barely familiar with it, it's got several stages which are named like Batch, beg for, beginning of the batch, batch auth, when authorizations come out, CONLIM batch end, et cetera.
There's a few other stages as well, but these are the ones that are important for us.
We have the normal time outside of batch and then BATCHBEG is a signifies that batches beginning now.
We also get these commands from P1C that all also come via and Q and it's it's on a different channel but a different way of getting it.
But it's got it.
It's not an MQ message like we need to process, but it's it's a command which says.
That we are now getting batch begin so the the caching system is notified if these changes in the stage of the batch so it at the batch at each critical point.
This is announced to the caching system, so we're gonna announcement that there's (Batch begin.
Then we get announcement that is (Batch auth.
Now at batch auth, what does that mean?
That means that authorizations are coming in.
All the transactions are coming in all the time right?
(Batch Auth says we're going to extract the list of authorizations into the extract file at as at this point.
So all the authorizations that we have, that's what's going into the file then.
That file is take some time to be generated.
Takes a little time.
Sorry.
There we go.
Take some time to be generated.
Take some time to be transmitted comes over to here and then takes some time to get loaded.
So there's some time between (Batch auth and generating and transmitting and loading the file.
Then we've got that data over in the caching database.
What about the transactions that happened just a few seconds after BATCHAUTH?
OK, they have been coming through NRT messages, right, because we gotta, we got an authorization, there was a change to the account.
That processing is still going on during batch, and that means we've got a near real time message with an update for the available balance for that account before we've got a chance to get the file loaded.
So there's a timing mismatch, right?
So how we resolve that is we store these MQTT messages normally under normal times we get an MQTT message, we put it in the database. Done.
Very simple.
During the batch process, once we've seen (Batch auth, we can't apply this or we'll put the latest record into the database and then we'll load the not latest record in the database.
We don't want that.
So these NRT messages we need to store them.
So we will apply them, you know.
And now I need to cover something else about petitioning data.
We'll.
I'll come back to that in a minute.
So we we do apply them to the database so that things are up to date, but we also keep a copy of them so that we can reapply them after we've loaded the data from the file.
Now I do have to cover it now the in the caching database.
It's a little bit complicated.
Ah, we have to have yesterday's data and today's data, because we're going through a time where we're getting files and it might take a couple of hours for us to get these files generated, transmitted and loaded and for everything to get, you know, get ready.
So during that time, let's say we'll choose day and the batch is running for Wednesday morning and we're gonna be using Wednesday started all but the new data, we can't switch that straight away when we load it into the database, it's not visible to the client sending a request in.
So if you send a request in, Umm and the cache service inquiry service you know is reading the database and responding, it's going to be using Tuesdays data, right?
And it's going to be that Tuesday's data is going to be updated with the latest record from the NRT message and that keeps Tuesday up to date, but we're not gonna update Wednesdays data because we don't have it yet, not until we've loaded the files.
When we load the files, we're loading them into a different partition for Wednesday.
That petition is not visible to the client at the moment.
It's not visible to these cached services.
It's in the database, but we haven't switched over to it yet, right?
So we've got these two different datasets going at the moment.
That's what makes it a little bit tricky, and that's what this is talking.
This diagram is trying to explain is that from (Batch auth we start storing the NRT messages for authorizations, and we do that until (Batch end as at batch end, everything is uh In Sync again from for accounts it's a little bit different for accounts we do it from CONLIM.
From that point in the batch, we start studying the NRT messages so that we can reapply them after the file has been loaded.
Multicurrency, we do it from the beginning as well.
So this is a that's a multicurrency auth.
McNair as multicurrency auth MCWP as multicurrency wallet balance, and it's the multicurrency wallet transfer.
OK, so there the NRT messages and when we store them after we've reached (Batch end, there's some quick.
Well, this is a.
This is the point after batch end where we switch over from Tuesday's data to Wednesday's data and then we're normal.
We're in the normal processing time again on Wednesdays.
Data whereas we started off on Tuesdays data.
Does that make sense or do I cause it's little complicated?
Does that make sense or do I need to clarify anything on that?
Please shout out.

Gadde, Ramesh   51:21
So how?
How many times the batches runs every day?
Let's check.

Kernahan, Richard   51:25
Yes.
So that runs once a day or sometimes not on some days, but generally once a day.

Gadde, Ramesh   51:32
OK.
So and and if there is an issue with the caching is if let's say if it's unavailable for some reason.
So the message is gonna queue.

Kernahan, Richard   51:39
Yeah.
OK.
I'll come back to problems at I've got that on the list.
I'll talk about problems first half first.
Well, we'll talk about it is supposed to work.
Uh loading file, so we're done.
Initial files.
Daily files.
OK, alright, now performance time.
The networks blazingly fast, so these files, even large files, get transmitted pretty quickly.
The 33 GB account file took 8 minutes.
I think from memory 8 minutes to load 33 gigs 8.2 million records, so that was pretty good.
It loads into a a low table which doesn't have any index on it, which is the fastest way to do it.
You take all constraints off the table, so we have a load table which is like a copy of the structure of account, but it's just for loading just today's data so we can load it really quickly into that because if you're updating an index at the same time it takes longer.
So we do that is one step and once we've loaded the data from the file into the database, then we've got the data in the database in an account load table and there's the real account table with a petition for Wednesday.
So we copy the data over, insert it from this account, load table into the Wednesday petition for the real account table, and that takes about that takes longer because you're updating the index, building the index at the same time.
So 8.2 million records that took about 15 minutes.
So altogether, with more volume full volume, I think it's 504040 minutes probably to load fully load all of the account data.
So this process elapsed time could be an hour or two depending on how quickly the files come out.
But like I said, some of the files come out early and BATCHAUTH others don't come out till CONLIM, which might be an hour later.
So this entire loading process might be going on for a couple of hours or so.
It seems, how do we?
How do we know when P SP1C is up or down?
Uh, right there is a there's a message that we can send over MQ umm to P1C.
It's called XPH, which is ping host, so it's very simple message.
We just ping it and P1C responds and say yes, I'm.
I'm up now that has been enhanced recently to give more information.
It used to just say yes.
Hello I'm here and that would show that you have connectivity and that P1C processing, no, it would just show connectivity what it's been enhanced to do is provide the batch status which is a two letter code which tells us exactly where we are in the batch.
The diagram I showed you before with the different stages and the batch.
It's more complicated.
There's more stages and then I showed and some of those stages will tell us that P1C is not available.
Umm, there's a table.
There's a list of like 10 codes, so for a couple of those codes it's not available and that's the one or two minutes in the morning in the afternoon, early, early in the batch and late in the batch where files are closed and P1C just is not processing.
So if we send an XPH, we can get back that too letter starts and we know whether P1C is available.
Umm, how does how do we how does Infinity connect now?
It's it's doing, it's getting transaction requests from clients, passing them straight through to P1C at at a rate of I don't know.
I think maximum they said 20 TPS, so it's significant but not monstrous.
Umm.
And so we're sending a lot of transactions all the time.
If we start being unable to send to P1C and then we know it's down and we can send an ex pH.
If we don't get a response, then there's a network problem and it's down as far as we're concerned.
If we get the response and it says it's unavailable, then no, it's.
We also know it's down and we're standing in when I say we're standing in a mean for the the caching system is standing in.
These cache services are responding to requests from the database instead if yeah, so Infinity Connect is doing it and parlor is doing it as well.
Paula can also sense does the same parallel kind of processing, same kind of processing to check if P1C is available?
Umm and Pala also mirrors the same logic that Infinity connect us to know at what stage we're at.
So it predicts whether or not these caching services are standing in or not.
Why does it need to do that?
Well, let's take the example of LSR in the forwarding.
The record so lost and stolen request comes in.
P1C is down, so the cache service does.
It updates the database and also stores the original request modified now with the new account number in the forward table in the caching database.
So the forward table is a table which stores these MQ records ready to go to P1C.
But P1C is down, so we can't send them.
How does Pala know?
When it's up again, it's doing X's.
So Pala, does XH calls every second or so to P1C when it thinks it's down and as soon as P1C comes back up again and says it's in a state where it's ready to accept records, Pala will read these records from the forward database from the forward table and send them one at a time to P1C.
So that's how the LSR gets over to P1C later.
Now the flags I talked about, how we're going initially initially all requests and inquiries are going through the CF if at all possible. Umm.
And in six months time, we want most of the requests to get served out of the caching services and out of the database, right?
So that change in policy can be set by that flag.
So at the moment, I think what's the enabled means like it's it's going to be served from the caching service if necessary.
If P wants is down, then it will be and that's how it's going to be set initially I think.
But later in six months time, I'd expect all the inquiries to be set a always on S, that it means when the request comes in, it will be served by the database.
Instead, it will be served by the caching services reading from the database.
So that's always on.
And we can disable a cache service as well if we if we don't want it to be used even if P1C is down, you say disable it.
Well, it's just not going to be that that service is simply not available for that minute or so while P1C is down.
OK.
So that's loading the initial files dailies.
Ohh, NRT messages, I I won't go into detail, but I I did cover that the West storing these NRT messages were loading the files after we load the files, we apply those stored in our team messages on top because they are later than whatever records we got supposed we got and available balance record from the file.
We put it into the database, we get another available balance record from NRT that's later.
So we're gonna clobber that first that file record with the NRT record and use that instead.
So that's the merging process that keeps the Wednesdays data up to date, and Tuesday's data up to date until we get to the end of batch and we're ready to switch over.
So there's this concept I implied, but I didn't express I didn't make clear of of the effective date that the effective date is what the caching services which partition they're caching services are looking at.
So that is the effective date Tuesday.
So it reads out of the Tuesday partitions of those tables, or is the effective date Wednesday, so it's reading out of those petitions and at the end of the batch we do the switch officially, do a switch from power.
Does that actually updates the database?
There's a table in the database with the batch date in it, so that's all it has in it.
It's just the batch date, so we update that batch date and then send a signal.
Uh command signal to IC, so tell everybody all of these IC6 IC servers get a refresh message which says OK, please go to the database and read the latest effective date and that's your.
That's your effective date to use from now on, so that's how it's synchronized.
It's.
Yeah, it's intrinsically complex.
Alright, let's talk about problems network.
Well, I forgot network problems here.
Now we're not getting anything.
That's gonna have to be solved if we've got network problems here and we can't get something through to MQ and that can happen, right?
That we see that quite often that some kind of network issue or or they could be an MQ issue itself like the net we can we can communicate to your cube it there's a queue wrong or something's gone wrong with a queue that can occur as well.
In that case, the logs in Infinity Connect are gonna show that there's MQ problem.
Normally has to be fixed.
Uh, either it's configuration and we're pointing to the wrong queue or there's just a problem.
If it's runtime, it's probably just a problem in the MQL area, which can happen sometimes.
Umm all P1C if we've got other problems that could be that P1C is uh.
And able to process it.
We think it should process it but it but it errors out instead.
There, that's another class of problems.
We could have database issues, right?
So yeah, some of the tricky things that happened with database.
Ohh I should make clear there are constraints here right with?
Naturally, there are going to be constraints with having a database that's In Sync with P1C.
Once we're going into production, you just can't Willy nilly change this database and still have the caching system working 24/7.
So the constraint is, uh, we're stuck with the database as it is largely.
And if we wanna modify it, you can add columns to the end of the table so we can add new fields to the to the file at the end, but that's pretty much all you can do.
You certainly can't take fields out or changing field names is very difficult.
Umm, so this is gonna be.
OK.
Yeah, it's kind of we're we're stuck with the way it is when we go into production and we can add on to it, but we really can't go back and change things very easily.
You can understand why when we think about, well, we've got files coming in which you know the file format got extracted by P1C and has to match the the column format.
The table format in the database, et cetera, ftpd, we could have problems with transmission.
We did have some problems early on with TLS.
The these Files Go to FTPS.
Itch is well secured.
TLS secured FTP file transfer protocol so we could have communications issues like network issues, forgetting the files over.
We could have certificate or password problems with the FTP server or using pureftpd for the server.
Here we could have space issues on the disk.
So there needs to be monitoring on the disk.
Now this 500 gigs is plenty of space.
We'll probably get 100 gig of files in total per day, and when they're loaded, those files are deleted at the end of the batch.
So a lot of files are deleted as soon as they're loaded.
Others, excuse me.
Like account available auths, some of those important files we have to keep until the end of batch because just in case there's a problem, we need to restart.
But at the end of batch, they're all deleted, so space should not fill up on this disk.
If it does, that's a problem.
Cache.
We could have problems in the cache service code.
I'm sure we're going to.
We have done, you know, to two years of work in six months, so there's going to be defects here.
Uh, but you know the way we're set up, I think we can get them fixed and back into production pretty fast.
Umm yeah, it's probably said the documentation is not perfect at the moment.
We've been running hard to build code and get get things working.
Uh, we will be focusing more on.
Well, we've still got performance testing to do and that takes priority over documentation as well.
And we'll get to documentation.
So for the support guys, we'll be giving you support.
We can to help make things easier in the first few weeks, but we'll we'll get to documentation and we'll get that all done in the next as the weeks go on.
Check time not going over time, sorry.

Mackellar, Alasdair   1:04:56
I just have a quick question for me.
Based on the diagram and when you mentioned about MQ going down which can happen, I take it that's the same it Infinity connect regard that the same as the P1C being and batch the connection is down and the automatically goes into hitting the caching database instead.

Kernahan, Richard   1:05:01
Yep.
That's correct.
Yeah.
If we have any of these problems like MQ is down, then caching then then the caching system will stand in.

Mackellar, Alasdair   1:05:17
OK.
OK, cool.
That's. That's good.
It's just part of what we're looking to test and as can we just take the MQ down to kind of get Ken rather than try and go in and simulate a batch within PC penalty, yeah.

Kernahan, Richard   1:05:35
Yeah.
That's right.
It's those two different things.
It's like, yeah, if we can't communicate over MQ or we're not getting through, it's the same thing for us as P ones that are being down unless we can actually get through to P1C and get things processed because sometimes we can talk to P1C, but it's not ready to process.

Mackellar, Alasdair   1:05:46
OK, excellent.

Kernahan, Richard   1:05:54
So it actually responds with a particular message saying we're not available for processing at the moment.

Mackellar, Alasdair   1:05:55
Hmm.

Kernahan, Richard   1:05:59
That can happen as well.
Any of those things happen.

Mackellar, Alasdair   1:06:01
And.

Kernahan, Richard   1:06:02
We stand in and stand in means any requests coming through inquiries or updates get handled by these cache services out of the database.

Mackellar, Alasdair   1:06:11
And and last question, I promise he when an apologies you've already kind of touched on on the coming back up and everything, so apologies for you will be repeating yourself and I've I'm sorry but when and would they wouldn't stand in mode we've had there multiple API calls of command they've all hit the caching database.

Kernahan, Richard   1:06:24
That's right.

Mackellar, Alasdair   1:06:35
Sent response back and when P1C comes back up, how quickly is what's happened during Standin reflected into P1C?

Kernahan, Richard   1:06:42
Yeah.
The question, yeah, yeah, good question.
OK, so if we have, I don't know, 2 correct, somebody can correct me if you're if I'm wrong and it's not 200,000 transactions a day, but that's kind of what I'm thinking in terms of umm, then busiest is like Navneet 60,000 hours 1000 minute so thousand a minute at best at highest and 2% are updates.
So that's.
20, OK, so we only have 2020 updates stored in the in the forward table to send.
Now normally an update takes you know less than 50 milliseconds.
So even if we wait for the response before we send the next one, which is what we're doing at the moment, that's one second.

Mackellar, Alasdair   1:07:22
OK.

Kernahan, Richard   1:07:28
So we'll clear, we'll clear the backlog of the messages that have been stored.
We'll clear that very quickly if it's 2000 messages that get stored, umm, I think we're still clear that pretty fast.

Mackellar, Alasdair   1:07:37
Pixel.

Kernahan, Richard   1:07:48
We have yet to do the performance tuning on this to make sure, but I you should think in terms of of less than 30 seconds I think.

Mackellar, Alasdair   1:07:50
Yeah.

Kernahan, Richard   1:07:58
And which case it reduces the need to think about what if we get other transactions happening during the same time when someone's making a request using a token which we haven't sent through yet.

Mackellar, Alasdair   1:08:06
No.

Kernahan, Richard   1:08:09
Well, umm, if we do it quickly, that's very not likely to happen in the worst case is.
Yeah, that's an inquiry, but it it doesn't work.
They tried again.
It does, right?
So highly unlikely.

Mackellar, Alasdair   1:08:20
OK.
Yeah, yeah.

Kernahan, Richard   1:08:21
Yeah, does entity question OK?

Mackellar, Alasdair   1:08:24
Yes, it does.
Thank you very much.
Thank you.

Ali, Tahir   1:08:28
Hey Richard, the caching databases and Oracle database correct.

Kernahan, Richard   1:08:32
Yes, Oracle Exadata database.

Ali, Tahir   1:08:35
OK.
And with the failover capabilities, multiple node or just one now?

Kernahan, Richard   1:08:39
Yeah, it's in Little Rock and Phoenix.
Umm, but yeah, that's right.
With the replication between the two.

Ali, Tahir   1:08:48
OK.
And within the data center, any replication like Little Rock, Little Rock either.
Do you know the single node?

Kernahan, Richard   1:08:55
Don't know question for the DS.

Ganji, Shekhar   1:09:00
Yeah, it's a two node, it's two node cluster.

Ali, Tahir   1:09:00
I.

Ganji, Shekhar   1:09:04
It's a primary and standby, but yeah, there's no failover capability within the within the within the data center.

Ali, Tahir   1:09:15
OK.
And and the replication is happening through Golden Gate.

Ganji, Shekhar   1:09:22
What does it stand by environment?
It's not a Golden Gate, it's a primary and data guard.

Ali, Tahir   1:09:28
OK, so in case of any issues, what will be the process to fail over?

Ganji, Shekhar   1:09:35
I it it depends on what type of failure right.
You can always do a switchover as part of the maintenance.
What we normally do like as a patching, you can do a a switch over to the other data center and be active there.

Ali, Tahir   1:09:52
And who will control that switch over?

Ganji, Shekhar   1:09:56
So we are trying to.
Create a a.
We are working on getting the resolve automation enabled like any other applications we have which will be controlled by the lower the application team supporting it.

Ali, Tahir   1:10:12
OK.
With the result and they this this database like it will come under part of Infinity Connect application or it will come under P1C mainframe?

Kernahan, Richard   1:10:28
It's Infinity connect, it's mid range.

Ganji, Shekhar   1:10:30
I think it's right.

Ali, Tahir   1:10:31
And mid range, OK.

Kernahan, Richard   1:10:32
Yeah.

Ali, Tahir   1:10:41
Now I know that Infinity connect all the previous ones that are with the EPC and FPC, they are all live and live systems, correct, active, active.
If they are linked to two data centers, both the data centers are active, so that's why like I was asking about the database code questions now in is.
In this particular, we don't have active active the database, so is Infinity.
Connect the Dr side is not active or is it pointing to one of the?

Kernahan, Richard   1:11:16
Right.
OK, so we've got.
That's correct.
Yeah.
We have an active site, say Little Rock, and then Phoenix is standby now for in for JDBC we have both addresses in the JDBC URL.
So will the Oracle driver will work out which one is active, so there's nothing for the code to do for the application to do?
It'll talk to whichever one is active, so if that fails over, there's no interruption.
Almost no interruption.
However, for loading files we have a.

Ali, Tahir   1:11:45
OK.

Kernahan, Richard   1:11:50
We have a constraint where the SQL loader program that I mentioned which loads the files into the database it's limited.
It has to know exactly which server you're talking to, so it can't.
There's not enough easy failover you.

Ali, Tahir   1:12:03
It will be OK that one place that.
Yeah.
So something happens.
Jake assumed that if something happens to the Little Rock, David, like data center itself, and you everything on there, then we'll have to set up a whole process to load all those files in Phoenix.

Kernahan, Richard   1:12:12
Yeah, exactly.
We're going to set up the whole process.
What we have to I'll tell you what we do.
We change the configuration for power to point to umm uh.
PDC to point to Phoenix, but we have to manually change that configuration to point to feel like restart it and the files are still gonna be coming to the Little Rock server here.

Ali, Tahir   1:12:32
Yeah.
Yes, assume.

Kernahan, Richard   1:12:36
If this Little Rock server is down, though, there's a shadow installation of Pala on Phoenix, so the process doesn't need to be set up again.
The application everything is there.
What does need to happen though, is this part here parlor and the PCO disk?
Uh, that is no longer a Little Rock.
That's now Phoenix and P1C needs to send the files to the Phoenix server because we just lost everything in Little Rock, right?
So yes, that would be a major problem.
We uh.
No, it'd be work.
So we'd have to retransmit those files and then load them.

Ali, Tahir   1:13:11
That it will, it will leave work and on top of it like again what you specify like documentation is still pending.
But like these processes and these failover processes, we used to be documented as well as part of that documentation please.

Kernahan, Richard   1:13:26
Yeah, of course.

Gadde, Ramesh   1:13:29
So who controls the parlor?
So is, is.
Is there a Bulkload, program or what?

Kernahan, Richard   1:13:34
Yeah, that's Bulkload, program.

Gadde, Ramesh   1:13:34
What exact?

Kernahan, Richard   1:13:35
Yeah, it.
Yeah, it used to be called Bulkload,.
We've renamed it.
Yeah, same same thing.
Well, it's been enhanced now.

Gadde, Ramesh   1:13:42
Which team supports that?
Because if in case of that like.

Kernahan, Richard   1:13:43
That's that is saying.
That's the the whole it's part of.
It's part of the caching system, so you can really think of this.
Uh, this this whole lower part of the diagram, including the cache services is all the caching system which has been added to straight Infinity Connect.
So Infinity Connect doesn't have higher availability, right up 1C is down.
Well, it's down.
Umm.
So all the high variability component is.
Let me draw it.
Pointer with a pen.
Here we go.
So it's really if there's a caching services here, it's all of this and the extract.
And Yep, all of that, all of that is the caching system, which has been added to Infinity Connect.
And this is all umm or all of this is how about his team?

Gadde, Ramesh   1:14:40
And OK.

Kernahan, Richard   1:14:46
OK, I've conscious and I've gone over time and number of people are on hold.
But I'm happy to answer any other questions if there are any.

Singh, Rajneesh   1:14:55
Ohh, you're Richard.

Gadde, Ramesh   1:14:55
So.

Singh, Rajneesh   1:14:56
I have one so as you said, we have to change that database connection manually for the Pala, right?
So in that case, we'll have to go and ask mainstream to send the files again.
So do we know the how do we request the files?
Do we need to?
Mention any job name or how do we get the files?

Kernahan, Richard   1:15:16
Yeah, I don't, I don't.
I don't know.
That hasn't been all that that kind of scenario hasn't been fleshed out in detail at the moment in that you're talking about the scenario where the whole Little Rock just goes away entirely because of the tornado, right?

Singh, Rajneesh   1:15:33
You know.

Kernahan, Richard   1:15:34
Yeah. So.
I did talk to the mainframe guys.
They said it's not that difficult, so they're just, they'll switch the IP, rerun the transmission jobs and we'll get the file sent over to Phoenix startup power on that side.
It's already pointing to the PDC database, so it will point to the active database and we started off with load the files and we're good.

Ali, Tahir   1:15:53
Yeah.
Right, right, right.
Yeah, I'll.
I'll add to Rajneesh questions if we know exactly which Mainframe job they have to trigger.
That means life is because, like when we reach out every time from mid range to a mainframe team and say like hey we need this farm to be rerun, all the ads gave us the job name don't give us file and we don't know how the file name works.

Singh, Rajneesh   1:16:14
Really.

Ali, Tahir   1:16:19
Give us the job name.

Kernahan, Richard   1:16:21
Yeah, I appreciate that.
I agree you need that information.
I don't have it on top of my head and it we all agree, we all agree it needs to be in the documentation before we get finished. Yep.

Ali, Tahir   1:16:27
No, no, we we, we.
Yeah.
And we don't want we don't want, like we don't expect you to.
Like remember everything, nobody does, so just just to remember that these needs to be part of our documentation.

Kernahan, Richard   1:16:43
Yeah.
Yeah, I agree. Yeah.

Gadde, Ramesh   1:16:46
Uh, rich, rich at one more question.
So is it another call it's going to be for CSP that customers like PIN, I think?

Kernahan, Richard   1:16:53
Ohh CSP.
Well, OK, yeah, it's a good question.
So OK, so CSP is another application which talks to the HSM's.
It's only needed for a couple of things for set PIN, get, PIN and CVV to get the CVV for card so that you can answer that question in GCD which is an inquiry about card information.
Umm, so So what?
Yep.
We have a couple of special services.
Uh for get pin and set pin to be high availability.
That's.
Yeah, probably separate call.
It's.
I'll just cover briefly.
We have a service in Infinity Connect for.

Ali, Tahir   1:17:39
No.
If if it is going to take it like, I'll suggest that we actually.

Kernahan, Richard   1:17:43
Ohpas, there's.
I just cover briefly.
So we've got services in, in IC which are high availability services.
They cooperate with some similar services in the XSP Java app, which is just, it's just another Java app on the diagram here.
Umm CSP cents for customer select PIN.
It does more than that, but it basically talks to the HSM's so that is it.
You know this talk to you about these services.
It talks to the HSM, doesn't need the mainframe and it can then, you know, set the offset so the PIN offset in the database so it can effectively set the pin and it can tell you what the pin is within encrypted sent an encrypted PIN back to the requester.
That's basically all there is to say about CSP I think.

Singh, Rajneesh   1:18:36
Does it use MQ?

Kernahan, Richard   1:18:36
Unless you've got some specific questions, that's also part of the same team.

Singh, Rajneesh   1:18:42
No, no.

Gadde, Ramesh   1:18:42
And is a.

Singh, Rajneesh   1:18:43
Does it use MQ CSP?

Kernahan, Richard   1:18:44
And CSV does not use them in for the purposes of MPMS.
CSP does not use MQ.

Gadde, Ramesh   1:18:53
How does it connect to HSM's?

Kernahan, Richard   1:18:57
TCP.

Gadde, Ramesh   1:19:01
OK.
And is the code base is part of Infinity Connect MPC and Connie Connect code base or it has got different code?

Kernahan, Richard   1:19:07
Now it's, but it's a separate.
It's a separate application like Pala is, but it's all part of the same team. Oops.

Gadde, Ramesh   1:19:14
Yeah.
Can we?
Can we also get the CSP architecture diagram and because we are not pretty clear on that one, so I just want you to understand how how this works entire flow.
I don't want a high level, it just talks to HSM and it does get CVV, set, pin get.
When I I get that but like trying to understand the lying architecture and stuff like that.

Kernahan, Richard   1:19:34
I'm sorry I missed the question.

Gadde, Ramesh   1:19:37
So can we get the architecture diagram of CSP)?
I'm just trying to understand like the underlying architecture how it works.

Kernahan, Richard   1:19:45
Yeah, OK.
Sure, that'll be it.
Yeah.
OK, we can do that in another call.
There's a whole reference document which explains CSP and detail.
And with diagrams as well?
Umm, but essentially we are. Well, yeah.
Yeah, I think that's another call then really because it's really two out of the out of 32 services that we're talking about South.

Gadde, Ramesh   1:20:06
Yeah.

Kernahan, Richard   1:20:13
Yeah, it's probably more a deep dive for something else.

Gadde, Ramesh   1:20:16
So yeah, but then thanks for that and one more final question, Sir.
Sorry.
So we see that near real time messages. Good.
Can you go back to the diagram please once?

Kernahan, Richard   1:20:25
Sure.

Gadde, Ramesh   1:20:28
So in the near real time messages via MQ right from P1C2 caching database.
So is it gonna happen only for a specific account activities?
I I'm not for the any arts or product updates, so I'm trying to understand is it for everything or like it's only for special.

Kernahan, Richard   1:20:45
Well, it's for if there's a if there's an auth, if there's a new auth, then yes, if there's a change to the auth, then yes, we get auth authorisation messages.
If there's a change to the account.
Uh, it can't record then?
Yes, any any change, the account record triggers an NRT.
So pretty much anything, anything, any change to the available balance available balance in North tend to go together, right because we've got minus $100 off the account for $100 off.
So those two always happen with the transaction account doesn't happen as often, but if you change your address then the account record will get updated.
And similarly with multicurrency.
So I'm thinking of it pretty much as yes, every time there's a change on any of those records that that's relevant to us.
Now we don't have every single field of the account in our account table that that in P1C have got more more fields that they didn't need to extract.
And then I don't need to send to the caching database, but for anything that we care about, we get an NRT message on any change.

Gadde, Ramesh   1:21:57
OK.
And maybe P1C maintains, like certain amount of years of data, right?
Like maybe five years, six years.
Is there any uh data retention in the caching database?
Is it like 4?

Kernahan, Richard   1:22:09
A couple of days.
I mean we we really only need Tuesdays data while we're loading Wednesdays, and then when we switch over to Wednesdays data we really don't even need Tuesdays data anymore.
So it gets purged at the end of the Pallas loading. Umm.
And it's configurable.
You can keep the day's data just a safe, and so we could switch back if we had to, but the next day, Tuesdays.
You know, once we load it, Thursday's data, we're gonna delete Tuesdays data that, that kind of thing.

Gadde, Ramesh   1:22:41
Ohh.

Kernahan, Richard   1:22:42
And it's configurable the number of days, so you can assume that we're gonna have three days data in the caching database.

Gadde, Ramesh   1:22:48
But in that case, like how we will have this accounts data?
Historically, you're gonna load every day because as OK.

Kernahan, Richard   1:22:58
But Ohh well, that's where most of the.
Transiently, one that's different.
OK, there there are some permanent tables like customer tables are permanent.
Umm.
And OK, transactions got 18 months of history.
So when we purge transactions, we're not purging from a few days ago, we're purging after if it's older than 18 months, we'll get rid of those records.
Same for statements.
Thought for all the stuff that's replaced daily, all the parameters and authorisations we don't need Tuesdays data anymore.
Once we switch to Wednesday, right, we've got a complete list of all the account, all the authorizations on Wednesday.
We don't need that.
That list that's out of date for Tuesday for the accounts will have a complete list in Wednesday.
For for that customer records, they're permanent.
So they're not, they're not being purged at all because we get delta records each day for customers, which add and add and delete records to the customer table.
So when I'm talking about purging, I'm talking about the files that are likely to accumulate, which we don't need anymore if they get perched.
Does that make sense?

Gadde, Ramesh   1:24:21
Kind of so.

Kernahan, Richard   1:24:23
Well, OK, let's go through proper P1C parameters like corporate parameters, product parameters.
They're replaced daily, right?

Gadde, Ramesh   1:24:29
Umm. Understood.

Kernahan, Richard   1:24:31
So we get a complete list of those each day or we don't need an old list.
That's clear.
Right.
So that's parameters.
That's 40 tables for.

Gadde, Ramesh   1:24:37
Yeah.

Kernahan, Richard   1:24:39
For authorizations, we get a complete new list every day for the current list of all authorizations that are outstanding.
So we don't need old lists of those, so they're likely to accumulate and we purge them from the database.
But but the customer tables once we load all the list of customers and then each day we just get a delta which says add these customers and delete these customers and modify these customers.

Gadde, Ramesh   1:24:54
And the.

Kernahan, Richard   1:25:04
Once we apply those changes, we've still got a complete list of customers.
We're not purging anything out of that table.

Gadde, Ramesh   1:25:11
And the ship.

Kernahan, Richard   1:25:12
Yeah.

Gadde, Ramesh   1:25:12
So if it is every day like let's say if if you purge all the auths every day, right?
I mean, you're gonna get complete auth data every day and you reload it again with the partition.

Kernahan, Richard   1:25:23
Yes, yes.

Gadde, Ramesh   1:25:25
Same for the accounts daily complete load with the partition row.

Kernahan, Richard   1:25:29
Ah, that's at the moment.
It's a complete load, but I think it's going to be changing to a do one complete load 1st and then do a daily delta for accounts so that particular one we've got a possibly a change from their works.

Gadde, Ramesh   1:25:36
Umm.

Kernahan, Richard   1:25:48
So there are different there's different categories for different, yeah, different tables that different rules for different tables.

Gadde, Ramesh   1:25:48
And it.
Gotcha.
And one final question, so you you wanna use pure ftpd for file transmissions right from P1C to Paula or like whatever it is so it fails, right?

Kernahan, Richard   1:26:03
Yes.

Gadde, Ramesh   1:26:05
Is there any Team gonna get notified?
Because that's the.
That's a daily jobs, right?
I mean we we want it to be on top of it.
If it fails right, we need to coordinate and.

Kernahan, Richard   1:26:15
Yes, of course.
They all these processes and exactly there's. There's.
That's why this is intrinsically complex.
There's a lots of lots of things to monitor.
No.
So the P1C will know if the transmission failed and Pala will know if it didn't receive files.
So yeah, there are.
There's lots of room for Splunk alerts in this process.

Gadde, Ramesh   1:26:44
Yeah.
And who supports pure ftpd here?
That's why I don't know.

Kernahan, Richard   1:26:49
Who supports it?
No application team.
I mean no.
Well supports it.
Yeah, it it's. Yeah.

Singh, Rajneesh   1:26:54
It will be us, Ramesh, but we don't have much details about this extract file flow.

Gadde, Ramesh   1:26:59
Yeah, yeah, I think we need to know that probably that's so because if whatever.

Singh, Rajneesh   1:27:00
Umm, I don't know right and.

Ali, Tahir   1:27:05
But these are but hold on one minute left APIs should be like coming through the mainframe to Mainframe will initiate correct like P1 or Extract, not know when the files are coming so the initiation should be on the mainframe so that process we control there.

Kernahan, Richard   1:27:13
And my Prime Minister yet.
Yep.
FTP is is coming from the mainframe.

Gadde, Ramesh   1:27:23
OK.

Kernahan, Richard   1:27:25
That's correct.
Yeah.
So pure Ftpd doesn't really have to do much.
It just takes the file and puts it in a in a folder.
There's not much that can go wrong unless the TLS doesn't work.

Ali, Tahir   1:27:32
But I.
The first corporate policy that FTP we cannot use, you have to have either encrypted channels or something like that.
So are we planning to do that because that will be another PCI audit finding?

Kernahan, Richard   1:27:49
Yeah, well, join the queue.
I mean, we've got trans transmissions to HSM's in the plane text, not not not TLS encrypted either.
So I think, yeah, we can make that comment about quite a few things in the North America and the infrastructure.

Ali, Tahir   1:28:01
That's the.
That's the that will affect performance a lot.

Kernahan, Richard   1:28:08
No, I don't think so.

Ali, Tahir   1:28:10
Yeah, when you have the data in encrypted and coming through.

Kernahan, Richard   1:28:14
Sorry this this this is protected by TLS already, right?
This FTP transmission is protected by TLS.

Ali, Tahir   1:28:23
But STP is not allowed.

Kernahan, Richard   1:28:30
I thought FTP do you mean FTP as opposed to FTPS or SFTP?

Ali, Tahir   1:28:30
Then you have SFTP or.
Yeah, yeah.

Kernahan, Richard   1:28:36
Yeah.
OK, well so this is ftps.
This is FTP protected by TLS.
I think it's allowed.
It's not a PCI issue.

Singh, Rajneesh   1:28:57
K So currently when we are when we have exerted a patching right, we work with DBA team or to make the failover right we do the failover and application automatically connects to the active database.

Kernahan, Richard   1:28:57
But it's.

Singh, Rajneesh   1:29:13
But in case of this Extract, thing right you are saying we have to manually change something in the parallel program and we have to notify notify the P1C team as well right to send the files to the different server either Little Rock or PDC.

Kernahan, Richard   1:29:20
That's correct.
No, no, no, no.
Unless there's a disaster, we're not gonna move this power off the well.
So we've got this running in one IC server in Little Rock and it's installed, but not running in one server in Phoenix.
But unless this whole server has gone away, we'll keep sending files to the same place for simplicity, and then it will load, load them to the active.

Singh, Rajneesh   1:29:49
OK, so Pala can process.
Uh, OK.
Pala can process both sides right?
I mean database later log and PDC OK.

Kernahan, Richard   1:29:55
Yeah.
I mean, yeah, Yep.
Yeah, discussed it with the architects and they're OK.
Whether it goes to Little Rock or or Phoenix database, then don't mind umm.
So it'll be processed from the same place, so that that keeps things simple, right?
Mainframe will send it to the same place and.
But yes, when the the database is switching from Little Rock to Phoenix, we can't just do that Willy nilly and we don't, right?
There's a notification process and the team will need to.
The support team will need to make the change to Pala and restart it so that it's pointing to the right active database.
Uh, no.

Singh, Rajneesh   1:30:30
OK.
So we'll need to.

Kernahan, Richard   1:30:31
Much getting around that I would design it differently if I could, but we have to use SQL loader.
It's an Oracle tool and we don't control it.

Singh, Rajneesh   1:30:38
OK, so the config change devia will do or we have to do in the program.
I mean, how do we point that?

Kernahan, Richard   1:30:45
The config, the configuration they Card.Midrange.Support midrange will do that.

Singh, Rajneesh   1:30:47
Config here that will be on the server, right?
OK.
Yeah. OK.

Kernahan, Richard   1:30:54
I mean, we've got both addresses there just unformat one and comment the other one.

Ali, Tahir   1:30:54
And again, all the information.

Gadde, Ramesh   1:31:04
When one more question though, I think.
Shekhar confirmed that we're going to use this article editor.
It's a channel by using data guard right?
I mean, it's not good and get replication so as exactly like Rajneesh function if during the patching ohh of the caching database so we're gonna connect the application to the secondary node in the Phoenix the standby mode in the Phoenix.
And if so, like what is the data replication sync time?
Is it real time or like?

Kernahan, Richard   1:31:45
Was on a bear in mind for Pala?
Right.
It's job is to load the files during the batch process, so you don't want to be doing that atching during the batch process.
You'll have to do it outside that process.
If we're in that couple of hours while we're loading files, the files are being sent from P1C, so this is another factor that needs to be taken into account, right?

Singh, Rajneesh   1:31:58
Ohh.

Kernahan, Richard   1:32:05
Umm and coordinate with DBA so they can't DBA's now have a constraint.

Gadde, Ramesh   1:32:05
In.

Kernahan, Richard   1:32:10
They can't just do it anytime they feel like it.
It's gonna have to be coordinated just by reality with when P1C is sending the files and when we get them loaded.
If we're loading files, we need to load them uninterrupted until we're finished loading.

Gadde, Ramesh   1:32:21
Uh.

Kernahan, Richard   1:32:26
Then for the other 20 hours of the day, Pala isn't doing very much, so it's really low problem.
If you switch databases at that point.

Gadde, Ramesh   1:32:34
I understand that that that question I I got it.
I my question is not about Paula, mostly because I know.
I mean if it is a data syncing is happening or like FTP files are getting loaded we shouldn't patch it.
We have to wait for it to be completed, but like my question is more of like you know, real time.
Yeah, real time updates also would be happening in parallel to like once the data load is completed, let's say near real time updates are happening into the little drop database and we we decided to you know switch it to Phoenix, right?
I mean, I'm trying to understand how how long the data sync is going to take place between Little Rock and Phoenix.
So is it?
Is it near real time or like the replication takes like 10 minutes or ohh.

Kernahan, Richard   1:33:16
All I know and my understanding is it's very quick.

Gadde, Ramesh   1:33:19
OK, well, that's why I was trying to understand that from Shekhar.
So if he's in the call.

Ganji, Shekhar   1:33:24
Yeah, it it is near real time.
Ramesh, again, it all depends on if you have too much of workload on the primary.
I mean in the standby it generates so many archive logs right?
So and then it needs to send it to the other side and then it's going to replay those.
But, but most of our environment exams, some of the big environments are all near real time.

Gadde, Ramesh   1:33:46
Yeah.
Anyway, since we are doing after the fact of a main load, so it's going to be less data.

Ganji, Shekhar   1:33:50
Umm, yeah, yeah, yeah expense.

Gadde, Ramesh   1:33:51
OK Shekhar service.
It's gonna be like other way around as well, right?
I mean if you connect to Phoenix, if any updates happen in the Phoenix will go back to drop using data guard, right?

Ganji, Shekhar   1:33:59
Umm.
Yeah, I'm not sure why we would not go with Golden Gate option.
I'm not.
Yeah, I I was not part of discussion, but again something uh.

Gadde, Ramesh   1:34:13
Yeah, I get that.
So that's why the main questions I was asking because of this data sync issues and stuff like that to just.
Just to make sure that, uh, we we talk about it, you know, before going live. Yeah.
So is bringing it.

Ganji, Shekhar   1:34:29
Yeah.
Again, anytime the patching appliance Team coordinates it and they they don't like application to be there and then they would be doing a live patching, they can do that.
Some of the applications they cannot failover like example image Center.
They do the live patching, but it's again always a risk, right?
So they always make sure one week before a couple of days before they want the application to be switched over to other side before the actions matching.

Gadde, Ramesh   1:34:58
And most probably we shouldn't do this.
Kind of patching in the IPL window because IPL P1C will be anywhere down, so we shouldn't do Exadata patching because that time completely depending on the caching database, right?

Ganji, Shekhar   1:35:07
Good.

Gadde, Ramesh   1:35:11
So I think that those things should be, you know, we have to coordinate as an application team, I believe.
So yeah, that's.

Ganji, Shekhar   1:35:18
So image Center is on the same frame, they don't fail over they because they have some limitations the application because they need to stand up all the the Dr side of things before they actually do the failover.
So there are some challenges there.
So they don't fail over, they they like over the weekend, they do the patching and then they complete it.
They roll over through the node by node, but this this application is also sits on the same frame so that it be failed over.
If we cannot tolerate that outage.

Gadde, Ramesh   1:35:49
Yeah, yeah. And and what?
One final question, shaded so in in the in the in the situation of like a Little Rock and Phoenix data sync, right?
So both the nodes are read, write or it's the other data center there.

Ganji, Shekhar   1:36:00
No, it's in a data guard set up.
One side is only active in a Golden Gate setup.
You have both sides active both sides.
You can write to, but there are ways in Golden Gate where you can lock the users so that nobody can log in to make sure there's no data changes happening on both sides.

Gadde, Ramesh   1:36:10
Yeah.

Ganji, Shekhar   1:36:18
But in the data guard it you can you can open the database and other side and read only mode to look at the data or run some reports or select queries.
But you cannot do any data changes on the on the the Dr side, but the data for the data guard setup.

Gadde, Ramesh   1:36:34
OK.
In that case, like we, we expect an outage in in terms of you know failover time.
So we stopped Little Rock and you failover to Phoenix and connect to Phoenix that maybe take some time like maybe 15 to 20 minutes depending upon the, you know all other things.

Ganji, Shekhar   1:36:43
Umm.
Yeah, it depends.
Especially I'm giving an example of MBP.
They they have very tight slit.
They, their entire they follow through this resolve automation and they trigger the resolve automation.
No deviation involved, but in case we get involved for any issues, but otherwise they trigger the switch over and then it takes 7 to 8 minutes basically to actual you know for the database to come up through your and if it is an ideal time nothing going on.
It's pretty quick, right?
So if you have some activities in test to catch up, then that's where it might take a few minutes here and there. But.

Gadde, Ramesh   1:37:27
Yeah.
Yes, I'm passing error right?
It will be OK because MQ will be I mean sorry P1C will be up and running and they're taking that code.

Ganji, Shekhar   1:37:32
Yeah.

Gadde, Ramesh   1:37:34
So I think it's the the only problem will be like six months from now when all the enquiries are going to run from caching services that's that's when it's going to be real problem.

Ganji, Shekhar   1:37:42
Umm.

Gadde, Ramesh   1:37:43
You don't have Golden Gate replication, so those we can talk briefly when we come to that point.
But I think these are the issues we can see now.

Singh, Rajneesh   1:37:56
Yeah, I Shekhar, I have a question regarding this exerted a patching when it happens, right?
It is not not completing on one day right is like couple of days.

Ganji, Shekhar   1:38:01
Umm.

Singh, Rajneesh   1:38:06
They plan a change and do it.

Ganji, Shekhar   1:38:07
Yeah, aspecially.
What they do is they it all depends on how the frame, how big the frame is, right?
If you have a 6 node cluster or five node cluster, they have to do each host that takes a while.
But this image center once are only two nodes of.
I think it's a four node.
Yeah, this this will run through a couple of days, an entire week they take from Monday to Friday normally.

Singh, Rajneesh   1:38:29
Right.
In that case, so if we take this Extract, thing right when we are loading extracts we we will not know when exactly our database is going into the patching.
And I mean that's why we do the failover in advance, yeah.

Ganji, Shekhar   1:38:45
Correct.
Yeah, that's what I'm saying. Yeah.

Kernahan, Richard   1:38:46
OK, I actually my I'm just conscious that we've been an hour and 40 minutes so far and probably want to let people go.

Ganji, Shekhar   1:38:50
Yeah.

Kernahan, Richard   1:38:52
It sounds, however, like there's a a big need for a discussion about failover.
Who would like to be involved in that?

Gadde, Ramesh   1:39:00
Yeah.

Kernahan, Richard   1:39:01
Maybe we can have a separate meeting on that.

Gadde, Ramesh   1:39:06
Yeah, yeah.
Yes, we we need Richard and we we need Rajneesh Tahir myself.
I think we we can it's a Card.Midrange.Support you can add and along with the DBS.

Kernahan, Richard   1:39:19
Yeah.
Now just to the to.
Make the comment that wait two weeks out from going live.
So we're not having a discussion on like how should we fundamentally change the architecture as way too late for that.
Those decisions were made already.
So what's the point of the what's the focus of the meeting?
It's to understand the implications of failovers our own.

Gadde, Ramesh   1:39:41
Yeah, I think we we need to, we need to identify like, what is the stopgap until, like, you know from out to whenever the six months from or whatever it is like how we are gonna do failover and how handle excited a patching those are the key points to be discussed.

Kernahan, Richard   1:39:52
Yeah.
Yep, correct.
OK.

Ganji, Shekhar   1:40:00
I think you have to involve in engage appliance team as well with Manish Upadhyay in team handles the patching so you include them as well so.

Kernahan, Richard   1:40:00
All set.
Yeah, OK. Ohm.
So just think it's set up great.
All right.
Is there anything else we need to cover or otherwise we can wind up?

Gadde, Ramesh   1:40:23
Yeah, we we can wind up, Richard.
There's just a CSP and this stuff we need to reconvene.
That's it.

Kernahan, Richard   1:40:30
Who?
Who's interested in CSP?
We can have a smaller meeting on that.

Gadde, Ramesh   1:40:32
Cut admitted support group.

Ali, Tahir   1:40:34
Yeah, Card.Midrange.Support.

Gadde, Ramesh   1:40:34
That's it.

Singh, Rajneesh   1:40:36
And supportive, yeah.

Kernahan, Richard   1:40:40
OK. Yep.

Gadde, Ramesh   1:40:41
I think whoever is left in the pretty much.

Ali, Tahir   1:40:43
And and Richard in the documentation.
One more thing as well to add especially related to Splunk.
What kind of messages to check for these activities like we specified when PNC goes down comes up those messages because not everything is?
You know, like data wise will be in this plunk, but some particular log messages that we'll have to check.

Kernahan, Richard   1:41:11
Yeah, right.
So there's log messages have been designed for Splunk to make it easy to extract and get the.
Run Splunk queries and alerts.
Umm.
And the design document has a a section dedicated to Splunk.
What those messages are, and also what alerts are required and what kind of severity they have, things like that.
So we're used to doing a detailed job on that.

Ali, Tahir   1:41:40
OK, sounds good.
Thank you.

Kernahan, Richard   1:41:42
There's alright.
Thanks very much for your time as long meeting, but hopefully you got some some value out of it and we'll we'll forward to a few meetings in the future. Thanks.

Singh, Rajneesh   1:41:55
Thank you.

Kernahan, Richard   1:41:56
Right.

Mackellar, Alasdair   1:41:59
Thanks all.

Gadde, Ramesh stopped transcription
